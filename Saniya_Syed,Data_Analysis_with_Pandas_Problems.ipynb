{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bcdc476",
   "metadata": {},
   "source": [
    "# Data Analysis with Pandas: Problems 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2afcfc",
   "metadata": {},
   "source": [
    "This assignment focuses on integrating and analyzing data from multiple sources. You will use advanced Pandas techniques like merging DataFrames, handling missing data, and performing detailed time-series analysis to solve a new set of business problems. Two datasets have been provided for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b72b9c",
   "metadata": {},
   "source": [
    "## The Use Case: Multi-Source Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8de53d",
   "metadata": {},
   "source": [
    "The business owner, Ms. Kavita, now has two separate datasets: sales_data.csv (containing daily order details) and customer_info.csv (containing customer names and their city of residence). She needs to combine these datasets to gain deeper insights into her customer base and product sales. Your task is to use Pandas to link these two data sources and answer her questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21f148",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d4913",
   "metadata": {},
   "source": [
    "For each problem, write and execute the Python code using Pandas. The problems are designed to be solved sequentially. Load both datasets and use them as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf9b88",
   "metadata": {},
   "source": [
    "### Problem 1: Data Loading and Merging\n",
    "\n",
    "Your first task is to load both CSV files and merge them into a single DataFrame. This combined dataset will be the foundation for all subsequent analysis.\n",
    "\n",
    "Write Python code to:\n",
    "\n",
    "* Load sales_data.csv into a DataFrame named df_sales.\n",
    "* Load customer_info.csv into a DataFrame named df_customers.\n",
    "* Merge the two DataFrames on a common column. Choose the correct join type to ensure no sales records are lost.\n",
    "* Display the first 5 rows and the column information of the new, merged DataFrame.\n",
    "\n",
    "Hint: Look for a common identifier column in both datasets to perform the join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f54bf51-3bd7-43a9-a1b6-9c59c9442bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id customer_name product_id       product_name  quantity  \\\n",
      "0       101         Aarav    PROD004  Pistachio Delight         2   \n",
      "1       102          Siya    PROD004   Strawberry Swirl         3   \n",
      "2       103         Kiran    PROD004   Strawberry Swirl         4   \n",
      "3       104         Priya    PROD001     Chocolate Chip         1   \n",
      "4       105         Mohan    PROD004   Strawberry Swirl         1   \n",
      "\n",
      "   unit_price_inr  order_date  total_price_inr  customer_id       city  \\\n",
      "0           152.0  2025-07-01              304          1.0     Mumbai   \n",
      "1           193.0  2025-07-02              579          2.0  Hyderabad   \n",
      "2           226.0  2025-07-03              904          3.0  Hyderabad   \n",
      "3           138.0  2025-07-04              138          4.0      Delhi   \n",
      "4           177.0  2025-07-05              177          5.0  Hyderabad   \n",
      "\n",
      "                    email  \n",
      "0  customer_1@example.com  \n",
      "1  customer_2@example.com  \n",
      "2  customer_3@example.com  \n",
      "3  customer_4@example.com  \n",
      "4  customer_5@example.com  \n",
      "\n",
      "Column Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   order_id         100 non-null    int64  \n",
      " 1   customer_name    98 non-null     object \n",
      " 2   product_id       100 non-null    object \n",
      " 3   product_name     100 non-null    object \n",
      " 4   quantity         100 non-null    int64  \n",
      " 5   unit_price_inr   95 non-null     float64\n",
      " 6   order_date       100 non-null    object \n",
      " 7   total_price_inr  100 non-null    int64  \n",
      " 8   customer_id      98 non-null     float64\n",
      " 9   city             98 non-null     object \n",
      " 10  email            98 non-null     object \n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 8.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_sales=pd.read_csv(\"sales_data.csv\")\n",
    "df_customers=pd.read_csv(\"customer_info.csv\")\n",
    "df_merged = pd.merge(df_sales, df_customers,on=\"customer_name\", how=\"left\")\n",
    "print(df_merged.head())\n",
    "print(\"\\nColumn Information:\")\n",
    "print(df_merged.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308aa040",
   "metadata": {},
   "source": [
    "### Problem 2: Advanced Analytical Questions with Merged Data\n",
    "\n",
    "Now that you have the combined dataset, answer Ms. Kavita's more complex questions that require customer and sales information together.\n",
    "\n",
    "Write Python code to:\n",
    "\n",
    "* Find the total sales revenue generated from customers in each city.\n",
    "* Identify the top 3 best-selling products by quantity.\n",
    "* Determine the city with the highest total revenue.\n",
    "* Find the customer who has spent the most money in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "333cfb42-eaf7-47fd-bd50-df0c101a2290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sales revenue per city:\n",
      "        city    revenue\n",
      "0      Delhi   575918.0\n",
      "1  Hyderabad  1512031.0\n",
      "2     Mumbai   517665.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_merged['revenue'] = df_merged['unit_price_inr'] * df_merged['unit_price_inr'] \n",
    "city_revenue = df_merged.groupby(\"city\")[\"revenue\"].sum().reset_index()\n",
    "print(\"Total sales revenue per city:\")\n",
    "print(city_revenue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09eba1d2-a680-458d-bc38-01380633c102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 best-selling products by quantity:\n",
      "       product_name  unit_price_inr\n",
      "0  Strawberry Swirl          3869.0\n",
      "1     Vanilla Dream          3371.0\n",
      "2    Chocolate Chip          3058.0\n"
     ]
    }
   ],
   "source": [
    "top_products = (\n",
    "    df_merged.groupby('product_name')[\"unit_price_inr\"]\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(3)\n",
    "    .reset_index()\n",
    ")\n",
    "print(\"\\nTop 3 best-selling products by quantity:\")\n",
    "print(top_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbf516d8-5214-4e6e-895d-d8d4054ee459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "City with the highest total revenue:\n",
      "city\n",
      "Hyderabad    25054\n",
      "Name: total_price_inr, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "city_revenue=df_merged.groupby(\"city\")[\"total_price_inr\"].sum()\n",
    "top_city = city_revenue.sort_values(ascending=False).head(1)\n",
    "print(\"\\nCity with the highest total revenue:\")\n",
    "print(top_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efa5bcb6-9bd3-45c8-ad77-6213af9a51fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Customer who has spent the most money in total:\n",
      "   customer_id customer_name  total_price_inr\n",
      "0          4.0         Priya             9568\n"
     ]
    }
   ],
   "source": [
    "top_customer = (\n",
    "    df_merged.groupby([\"customer_id\", \"customer_name\"])[\"total_price_inr\"]\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(1)\n",
    "    .reset_index()\n",
    ")\n",
    "print(\"\\nCustomer who has spent the most money in total:\")\n",
    "print(top_customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aff789",
   "metadata": {},
   "source": [
    "### Problem 3: Cleaning and Filtering for Specific Insights\n",
    "\n",
    "Ms. Kavita needs to prepare a report for her marketing team. This requires some data cleaning and specific filtering.\n",
    "\n",
    "Write Python code to:\n",
    "\n",
    "* Identify and handle any missing values in the merged DataFrame. Explain your chosen method.\n",
    "* Filter the DataFrame to show all orders made by customers from 'Mumbai' for the 'Pistachio Delight' product.\n",
    "* Create a new DataFrame containing only the columns: customer_name, city, product_name, and total_price_inr for all orders that have a revenue of more than INR 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cea618d4-d994-4e56-85c8-2856207a3c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      "order_id           0\n",
      "customer_name      2\n",
      "product_id         0\n",
      "product_name       0\n",
      "quantity           0\n",
      "unit_price_inr     5\n",
      "order_date         0\n",
      "total_price_inr    0\n",
      "customer_id        2\n",
      "city               2\n",
      "email              2\n",
      "revenue            5\n",
      "dtype: int64\n",
      "\n",
      "Missing values after handling:\n",
      "order_id           0\n",
      "customer_name      0\n",
      "product_id         0\n",
      "product_name       0\n",
      "quantity           0\n",
      "unit_price_inr     0\n",
      "order_date         0\n",
      "total_price_inr    0\n",
      "customer_id        0\n",
      "city               0\n",
      "email              0\n",
      "revenue            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"Missing values before handling:\")\n",
    "print(df_merged.isnull().sum())\n",
    "df_cleaned = df_merged.fillna({\n",
    "    col: 0 if df_merged[col].dtype in ['int64', 'float64'] else \"Unknown\"\n",
    "    for col in df_merged.columns\n",
    "})\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ddd97c7-4b23-4400-82e2-aebe5baedf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Orders from Mumbai for Pistachio Delight:\n",
      "    order_id customer_name product_id       product_name  quantity  \\\n",
      "0        101         Aarav    PROD004  Pistachio Delight         2   \n",
      "20       121         Aarav    PROD001  Pistachio Delight         3   \n",
      "40       141         Aarav    PROD004  Pistachio Delight         4   \n",
      "75       176         Aarav    PROD005  Pistachio Delight         3   \n",
      "\n",
      "    unit_price_inr  order_date  total_price_inr  customer_id    city  \\\n",
      "0            152.0  2025-07-01              304          1.0  Mumbai   \n",
      "20           163.0  2025-07-21              489          1.0  Mumbai   \n",
      "40           150.0  2025-08-10              600          1.0  Mumbai   \n",
      "75           174.0  2025-09-14              522          1.0  Mumbai   \n",
      "\n",
      "                     email  revenue  \n",
      "0   customer_1@example.com  23104.0  \n",
      "20  customer_1@example.com  26569.0  \n",
      "40  customer_1@example.com  22500.0  \n",
      "75  customer_1@example.com  30276.0  \n"
     ]
    }
   ],
   "source": [
    "mumbai_pistachio = df_cleaned[\n",
    "    (df_cleaned[\"city\"] == \"Mumbai\") & (df_cleaned[\"product_name\"] == \"Pistachio Delight\")\n",
    "]\n",
    "print(\"\\nOrders from Mumbai for Pistachio Delight:\")\n",
    "print(mumbai_pistachio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a00bf757-fa97-4daa-9c79-0e6a4185a4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered DataFrame with revenue > 300:\n",
      "  customer_name       city       product_name  total_price_inr\n",
      "0         Aarav     Mumbai  Pistachio Delight          23104.0\n",
      "1          Siya  Hyderabad   Strawberry Swirl          37249.0\n",
      "2         Kiran  Hyderabad   Strawberry Swirl          51076.0\n",
      "3         Priya      Delhi     Chocolate Chip          19044.0\n",
      "4         Mohan  Hyderabad   Strawberry Swirl          31329.0\n"
     ]
    }
   ],
   "source": [
    "filtered_orders = df_cleaned[df_cleaned[\"revenue\"] > 300][\n",
    "    [\"customer_name\", \"city\", \"product_name\", \"revenue\"]\n",
    "].rename(columns={\"Product\": \"product_name\", \"revenue\": \"total_price_inr\"})\n",
    "print(\"\\nFiltered DataFrame with revenue > 300:\")\n",
    "print(filtered_orders.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8516281",
   "metadata": {},
   "source": [
    "### Problem 4: Time-Series and Product-Specific Analysis\n",
    "\n",
    "The business wants to understand how sales of specific products trend over time and how they perform on different days.\n",
    "\n",
    "Write Python code to:\n",
    "\n",
    "* Convert the 'order_date' column to a proper datetime format.\n",
    "* Create a new column named 'day_of_week' that shows the day name (e.g., 'Monday', 'Tuesday').\n",
    "* Calculate the total revenue for the 'Vanilla Dream' product each day.\n",
    "* Find the average daily revenue for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4da3e48-9852-47c7-91d5-41922dd1cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_cleaned[\"order_date\"] = pd.to_datetime(df_cleaned[\"order_date\"], errors=\"coerce\")\n",
    "\n",
    "df_cleaned[\"day_of_week\"] = df_cleaned[\"order_date\"].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "311bcfed-e161-4a33-92b4-ee23430d5856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total daily revenue for 'Vanilla Dream':\n",
      "   order_date  revenue\n",
      "0  2025-07-06  52441.0\n",
      "1  2025-07-09  44521.0\n",
      "2  2025-07-12  33489.0\n",
      "3  2025-07-19  16129.0\n",
      "4  2025-07-23  32400.0\n",
      "5  2025-07-29  13924.0\n",
      "6  2025-07-30  29584.0\n",
      "7  2025-08-01  14641.0\n",
      "8  2025-08-09  38025.0\n",
      "9  2025-08-16  47524.0\n",
      "10 2025-08-19  29241.0\n",
      "11 2025-08-23      0.0\n",
      "12 2025-08-27  40000.0\n",
      "13 2025-08-28  38809.0\n",
      "14 2025-08-31  34225.0\n",
      "15 2025-09-13  32041.0\n",
      "16 2025-09-18   7921.0\n",
      "17 2025-09-24  38025.0\n",
      "18 2025-09-26  25281.0\n",
      "19 2025-10-08  58564.0\n"
     ]
    }
   ],
   "source": [
    "#Calculate the total revenue for the 'Vanilla Dream' product each day\n",
    "vanilla_sales = (\n",
    "    df_cleaned[df_cleaned[\"product_name\"] == \"Vanilla Dream\"]\n",
    "    .groupby(\"order_date\")[\"revenue\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "print(\"Total daily revenue for 'Vanilla Dream':\")\n",
    "print(vanilla_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ca9a633-ef15-43e0-be3c-bfd6be963cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average daily revenue per product:\n",
      "        product_name  avg_daily_revenue\n",
      "0     Chocolate Chip       23708.000000\n",
      "1       Mango Medley       28678.066667\n",
      "2  Pistachio Delight       25459.437500\n",
      "3   Strawberry Swirl       24556.333333\n",
      "4      Vanilla Dream       31339.250000\n"
     ]
    }
   ],
   "source": [
    "#Find the average daily revenue for each product\n",
    "avg_daily_revenue = (\n",
    "    df_cleaned.groupby([\"product_name\", \"order_date\"])[\"revenue\"]\n",
    "    .sum()\n",
    "    .groupby(\"product_name\")\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"revenue\": \"avg_daily_revenue\"})\n",
    ")\n",
    "print(\"\\nAverage daily revenue per product:\")\n",
    "print(avg_daily_revenue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cae1e8-f9c1-4dd6-bdab-c57332f3af83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
